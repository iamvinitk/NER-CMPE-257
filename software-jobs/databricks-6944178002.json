{"absolute_url": "https://databricks.com/company/careers/open-positions/job?gh_jid=6944178002", "data_compliance": [{"type": "gdpr", "requires_consent": false, "requires_processing_consent": false, "requires_retention_consent": false, "retention_period": null}], "internal_job_id": 5644224002, "location": {"name": "Paris, France"}, "metadata": [{"id": 24059030002, "name": "Career Page Posting Category", "value": ["Field Engineering"], "value_type": "multi_select"}], "id": 6944178002, "updated_at": "2023-11-17T13:38:50-05:00", "requisition_id": "FEQ424R291", "title": "Senior Specialist Solutions Architect - Data Warehousing", "pay_input_ranges": [], "content": "(FEQ424R291)\n \nMission\nAs a Specialist Solutions Architect (Data Warehousing), you will guide customers in their cloud data warehousing transformation with Databricks which spans a large variety of use cases.\nYou will be in a customer-facing role, working with and supporting Solution Architects, that requires hands-on production experience with large-scale data warehousing technologies, and expertise in other modern data technologies such as Apache Spark\u2122.\nSSAs help customers through evaluations and successful planning of data warehousing workloads while aligning their technical roadmap for expanding the usage of the Databricks Lakehouse Platform.\nAs a go-to-expert reporting to the Specialist Field Engineering Manager, you will continue to strengthen your technical skills through mentorship, learning, and internal training programs and establish yourself in the data warehousing speciality - including performance tuning, data modelling, winning compete evaluations, and production migration planning.\n \nThe impact you will have:\nProvide technical leadership to guide strategic customers to successful cloud transformations on large-scale data warehousing workloads - ranging from evaluation to architecture design to production deployment.\nProve the value of the Databricks Lakehouse Architecture on customer workloads by architecting production-level workloads, including end-to-end pipeline load performance testing and optimization.\nBecome a technical expert in an area such as data management, cloud platforms, and architecture.\nAssist Solution Architects with more advanced aspects of the technical sale including custom proof of concept content, estimating workload sizing, and custom architectures.\nProvide tutorials and training to improve community adoption (including hackathons and conference presentations)\nContribute to the Databricks Community.\n \nWhat we look for:\n5+ years experience in a pre-sales or post-sales technical role with expertise in data warehousing - such as query tuning, performance tuning, troubleshooting, and debugging MPP data warehouses or other big data solutions. Maintained, extended, or migrated a production data warehouse system to evolve with complex customer needs.\nExperience in the design and implementation of data warehousing technologies including NoSQL, MPP, OLTP, and OLAP.\nTechnical expertise in scaling big data workloads that are performant and cost-effective - including technologies such as Delta Lake.\n2+ years of professional experience with Big Data technologies (I.e. Spark, Hadoop, Kafka) and production-level programming experience in SQL and Python, Scala, or Java.\nExperience with the AWS, Azure, or GCP clouds is highly desirable.\nExperience in Teradata, Oracle, and/or Netezza is preferable.\nFluent in French\n \nBenefits\nComplementary health insurance\nComplementary life and disability coverage\nComplementary pension\nEquity awards\nPaid parental leave\nGym reimbursement\nAnnual personal development fund\nWork headphones reimbursement\nBusiness travel accident insurance\nAbout Databricks\nDatabricks is the data and AI company. More than 10,000 organizations worldwide \u2014 including Comcast, Cond\u00e9 Nast, Grammarly, and over 50% of the Fortune 500 \u2014 rely on the Databricks Data Intelligence Platform to unify and democratize data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe and was founded by the original creators of Lakehouse, Apache Spark\u2122, Delta Lake and MLflow. To learn more, follow Databricks on Twitter, LinkedIn and Facebook.\nOur Commitment to Diversity and Inclusion\nAt Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics.\n \nCompliance\nIf access to export-controlled technology or source code is required for performance of job duties, it is within Employer's discretion whether to apply for a U.S. government license for such positions, and Employer may decline to proceed with an applicant on this basis alone.", "departments": [{"id": 4069106002, "name": "Field Engineering", "child_ids": [4001270002, 4002597002, 4077536002, 4077535002, 4076791002, 4070290002], "parent_id": null}], "offices": [{"id": 4005269002, "name": "Paris, France", "location": "Paris, France", "child_ids": [], "parent_id": 4033857002}], "compliance": null, "demographic_questions": null, "questions": [{"description": null, "label": "First Name", "required": true, "fields": [{"name": "first_name", "type": "input_text", "values": []}]}, {"description": null, "label": "Last Name", "required": true, "fields": [{"name": "last_name", "type": "input_text", "values": []}]}, {"description": null, "label": "Email", "required": true, "fields": [{"name": "email", "type": "input_text", "values": []}]}, {"description": null, "label": "Phone", "required": true, "fields": [{"name": "phone", "type": "input_text", "values": []}]}, {"description": null, "label": "Resume/CV", "required": true, "fields": [{"name": "resume", "type": "input_file", "values": []}, {"name": "resume_text", "type": "textarea", "values": []}]}, {"description": null, "label": "Cover Letter", "required": false, "fields": [{"name": "cover_letter", "type": "input_file", "values": []}, {"name": "cover_letter_text", "type": "textarea", "values": []}]}, {"description": null, "label": "LinkedIn Profile", "required": false, "fields": [{"name": "question_25414672002", "type": "input_text", "values": []}]}, {"description": null, "label": "How did you hear about this job?", "required": true, "fields": [{"name": "question_25414673002", "type": "input_text", "values": []}]}, {"description": null, "label": "What is your current notice period? (Include any additional notes on your availability/timeline to start a new role) ", "required": true, "fields": [{"name": "question_25414674002", "type": "textarea", "values": []}]}, {"description": "<p>Seeking insights on an example relevant to the Data &amp; AI landscape</p>\n<p>Include notes to set the context on your role, objectives, key technologies used and the outcome of the solution.&nbsp;</p>\n<p>Note: This will help provide a basis for a core part of an initial screen discussion.</p>", "label": "Provide a summary of an interesting/challenging Big Data architecture solution (POC) you have worked on, with particular focus on Cloud Data Warehousing. ", "required": false, "fields": [{"name": "question_25414675002", "type": "textarea", "values": []}]}], "location_questions": [], "file": "databricks-6944178002.json"}