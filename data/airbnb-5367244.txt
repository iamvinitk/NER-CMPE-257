Airbnb was born in 2007 when two Hosts welcomed three guests to their San Francisco home, and has since grown to over 4 million Hosts who have welcomed more than 1 billion guest arrivals in almost every country across the globe. Every day, Hosts offer unique stays and experiences that make it possible for guests to connect with communities in a more authentic way.About the Team
Analytics Engineers build upon the data foundation. We are looking for someone with expertise in metric development, data modeling, SQL, Python, and large-scale distributed data processing frameworks like Presto or Spark. Using these tools, along with first-class internal data tooling, you will transform data from data warehouse tables into critical data artifacts that power impactful analytic use cases (e.g. metrics, dashboards) and empower downstream data consumers. As an Analytics Engineer, you will sit at the intersection of data science , Product analytics and data engineering, and work collaboratively to achieve highly impactful outcomes.Data can transform how a company operates; high data quality and tooling is the biggest lever to achieving that transformation. You will make that happen.
Responsibilities:

Understand data needs by interfacing with fellow Analytics Engineers, Data Scientists, Data Engineers, and Business Partners
Architect, build, and launch efficient  reliable data models and pipelines in partnership with Data Engineering
Design and implement metrics and dimensions to enable analysis and predictive modeling
Design and develop data resources to enable self-serve data consumption
Build tools for auditing, error logging, and validating data tables
Define logging needs in partnership with Data Engineering
Define and share best practices on metric, dimension, and data model development for analytics use
Build and improve data tooling in partnership with Data Platform teams
Be a technical expert on data model usage
Own and review code changes to certified metric and dimension definitions
Manage communication of data model updates and changes across organization
Ensure data models are fully documented, and metrics and dimensions have clear descriptions and metadata

Minimum Qualifications:

Passion for high data quality and scaling data science work
6 years of relevant industry experience
Strong skills in SQL and distributed system optimization (e.g. Spark, Presto, Hive)
Experience in schema design and dimensional data modeling
Experience in at least one programming language for data analysis (e.g. Python, R)
Proven ability to succeed in both collaborative and independent work environments
Detail-oriented and excited to learn new skills and tools
Strong influence and relationship management skills

Preferred Qualifications:

Experience with an ETL framework like Airflow
Python, Scala, Superset preferred.
Effective story-telling  articulation skills  ability to convert analytical output into clear, concise, and persuasive insights  recommendations for technical  non-technical audience
An eye for design when it comes to dashboards and visualization tools
Familiarity with experimentation and machine learning technique

 