{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamvinitk/NER-CMPE-257/blob/master/code_temp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5875ae71-662e-4242-8b62-a33f655f353d",
      "metadata": {
        "id": "5875ae71-662e-4242-8b62-a33f655f353d"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "with open('Programming_languages.json', 'r') as file:\n",
        "    programming_languages = json.load(file)['PROGRAMMING_LANGUAGES']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b247504d-2fb3-4be7-bcc2-41b4b751e4f6",
      "metadata": {
        "id": "b247504d-2fb3-4be7-bcc2-41b4b751e4f6"
      },
      "outputs": [],
      "source": [
        "# programming_languages\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    # Remove HTML tags\n",
        "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
        "    # Remove special characters and digits\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    return text\n",
        "# cleaned_text = clean_text(text_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a203c2c4-ecb4-4927-9537-1426d218e378",
      "metadata": {
        "id": "a203c2c4-ecb4-4927-9537-1426d218e378"
      },
      "outputs": [],
      "source": [
        "data_folder = '..\\data'\n",
        "text_data = []\n",
        "for filename in os.listdir(data_folder):\n",
        "    with open(os.path.join(data_folder, filename), 'r') as file:\n",
        "        text_data.append(clean_text(file))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61a02cde-4d7a-4429-bb36-dcb02c134eb4",
      "metadata": {
        "id": "61a02cde-4d7a-4429-bb36-dcb02c134eb4",
        "outputId": "5642d9bc-d0bd-4381-8ecf-1311d66ce971"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10230"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(text_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5fdf236-da7c-419e-863c-3931b068c90b",
      "metadata": {
        "id": "b5fdf236-da7c-419e-863c-3931b068c90b"
      },
      "outputs": [],
      "source": [
        "# pip install nltk scikit-learn matplotlib wordcloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12ef2dfb-e5f9-4978-9fb6-3433ddc692e5",
      "metadata": {
        "id": "12ef2dfb-e5f9-4978-9fb6-3433ddc692e5"
      },
      "outputs": [],
      "source": [
        "# import nltk\n",
        "# nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12b70977-0d0d-43fa-9648-4d621c1e267d",
      "metadata": {
        "id": "12b70977-0d0d-43fa-9648-4d621c1e267d"
      },
      "outputs": [],
      "source": [
        "# !python -m pip install --user --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b218c6c3-204c-4808-a830-e0ead328db39",
      "metadata": {
        "id": "b218c6c3-204c-4808-a830-e0ead328db39"
      },
      "outputs": [],
      "source": [
        "# !pip cache purge\n",
        "# !pip install spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb1c5dbb-118f-4681-80eb-cb3d53eb92cc",
      "metadata": {
        "id": "fb1c5dbb-118f-4681-80eb-cb3d53eb92cc"
      },
      "outputs": [],
      "source": [
        "# !python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0478b5fa-b9ae-436a-b055-3249baa87c74",
      "metadata": {
        "id": "0478b5fa-b9ae-436a-b055-3249baa87c74"
      },
      "outputs": [],
      "source": [
        "# import spacy\n",
        "# import os\n",
        "\n",
        "# # Get the directory containing the about.py file\n",
        "# about_dir = os.path.dirname(spacy.about.__file__)\n",
        "\n",
        "# # Specify the path to the en_core_web_sm model directory\n",
        "# model_path = os.path.join(about_dir, 'data', 'en_core_web_sm')\n",
        "\n",
        "# print(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec1e7eae-8c67-4415-893a-a3507b72e729",
      "metadata": {
        "id": "ec1e7eae-8c67-4415-893a-a3507b72e729"
      },
      "outputs": [],
      "source": [
        "# import spacy\n",
        "\n",
        "# # Load pre-trained spaCy model\n",
        "# nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# def extract_entities(text):\n",
        "#     doc = nlp(text)\n",
        "#     entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "#     return entities\n",
        "\n",
        "# # Example usage\n",
        "# entities = extract_entities(text_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "658a3c15-0687-4e3c-8b75-5c7863a68b04",
      "metadata": {
        "id": "658a3c15-0687-4e3c-8b75-5c7863a68b04",
        "outputId": "997920c8-916b-4b30-8d4a-1c1011bd8f08"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The system cannot find the file specified.\n"
          ]
        }
      ],
      "source": [
        "!pip install stanfordnlp>=0.1.0,<0.2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c5028fe-9d29-4143-b919-5b5d464f5e93",
      "metadata": {
        "id": "5c5028fe-9d29-4143-b919-5b5d464f5e93"
      },
      "outputs": [],
      "source": [
        "import stanfordnlp\n",
        "def process_with_corenlp(text):\n",
        "    # Download the pre-trained model (if not already downloaded)\n",
        "    # stanfordnlp.download('en')  # Downloads English models\n",
        "    # Initialize the pipeline\n",
        "    nlp = stanfordnlp.Pipeline()\n",
        "    # Process the text\n",
        "    doc = nlp(text)\n",
        "    # Extract named entities\n",
        "    entities = []\n",
        "    for sentence in doc.sentences:\n",
        "        for ent in sentence.ents:\n",
        "            entities.append((ent.text, ent.type))\n",
        "    return entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4c0f859-aee3-4f0f-9bea-9fe98a3016d8",
      "metadata": {
        "id": "b4c0f859-aee3-4f0f-9bea-9fe98a3016d8"
      },
      "outputs": [],
      "source": [
        "# !pip install stanfordnlp --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb174ac6-75dd-4175-9215-a5ea930e3225",
      "metadata": {
        "id": "eb174ac6-75dd-4175-9215-a5ea930e3225"
      },
      "outputs": [],
      "source": [
        "# !pip install torch --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d0e2918-fdd0-4202-82d5-505837c54135",
      "metadata": {
        "id": "3d0e2918-fdd0-4202-82d5-505837c54135"
      },
      "outputs": [],
      "source": [
        "entities = process_with_corenlp(text_data[0])\n",
        "entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a75134e-e39d-463e-8d93-fb7dc0b83b4a",
      "metadata": {
        "id": "6a75134e-e39d-463e-8d93-fb7dc0b83b4a"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def extract_keywords(text_data):\n",
        "    # Concatenate the strings in text_data into a single string\n",
        "    concatenated_text = ' '.join(text_data)\n",
        "    # Use TfidfVectorizer with custom stop words\n",
        "    vectorizer = TfidfVectorizer(stop_words='english')\n",
        "    tfidf_matrix = vectorizer.fit_transform([concatenated_text])\n",
        "    # Get feature names (words)\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "    # Identify keywords using TF-IDF scores\n",
        "    tfidf_sum_per_word = tfidf_matrix.sum(axis=0).A1\n",
        "    keywords = [feature_names[i] for i in tfidf_sum_per_word.argsort()[::-1][:10]]  # Extract top 10 keywords\n",
        "    return keywords\n",
        "\n",
        "# Example usage\n",
        "keywords = extract_keywords(text_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b764843b-9750-4e08-9d1a-219ef4725139",
      "metadata": {
        "id": "b764843b-9750-4e08-9d1a-219ef4725139",
        "outputId": "8a21f823-f04d-4983-e6be-339571b196c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['experience',\n",
              " 'work',\n",
              " 'team',\n",
              " 'data',\n",
              " 'business',\n",
              " 'including',\n",
              " 'skills',\n",
              " 'role',\n",
              " 'teams',\n",
              " 'status']"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "keywords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ddc6bfc-2188-4157-b69a-586ffc4180b0",
      "metadata": {
        "id": "3ddc6bfc-2188-4157-b69a-586ffc4180b0"
      },
      "outputs": [],
      "source": [
        "def visualize_keywords(keywords):\n",
        "    wordcloud = WordCloud(width=800, height=400, max_font_size=110).generate(' '.join(keywords))\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "702a7d12-e290-4fa6-b38f-bb6cb94d915a",
      "metadata": {
        "id": "702a7d12-e290-4fa6-b38f-bb6cb94d915a"
      },
      "outputs": [],
      "source": [
        "# visualize_keywords(keywords)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def calculate_similarity(resume, job_description):\n",
        "    documents = [resume, job_description]\n",
        "\n",
        "    # Convert the documents into a matrix of TF-IDF features\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
        "\n",
        "    # Compute the cosine similarity between the two documents\n",
        "    similarity_score = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])[0][0]\n",
        "\n",
        "    return similarity_score\n",
        "\n",
        "# Example usage:\n",
        "resume_text = \"Experienced software engineer with strong programming skills...\"\n",
        "job_description_text = \"We are seeking a highly skilled software engineer...\"\n",
        "\n",
        "score = calculate_similarity(resume_text, job_description_text)\n",
        "print(f\"Similarity Score: {score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1I3hDZ0TdBYj",
        "outputId": "d6b2bf36-9242-4706-e533-b182d814f660"
      },
      "id": "1I3hDZ0TdBYj",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity Score: 0.16839750037215276\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "def calculate_similarity(resume, job_description):\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "    # Process the text using spaCy\n",
        "    resume_doc = nlp(resume)\n",
        "    job_description_doc = nlp(job_description)\n",
        "\n",
        "    # Calculate the similarity between the processed texts\n",
        "    similarity_score = resume_doc.similarity(job_description_doc)\n",
        "\n",
        "    return similarity_score\n",
        "\n",
        "# Example usage:\n",
        "resume_text = \"Experienced software engineer with strong programming skills...\"\n",
        "job_description_text = \"We are seeking a highly skilled software engineer...\"\n",
        "\n",
        "score = calculate_similarity(resume_text, job_description_text)\n",
        "print(f\"Similarity Score: {score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tdmr4Mq0dhPe",
        "outputId": "1f595fa1-2bc1-4a3f-bb62-9643eef742c1"
      },
      "id": "Tdmr4Mq0dhPe",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity Score: 0.5396360952066532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-e888ebcc57b2>:11: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity_score = resume_doc.similarity(job_description_doc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarity score increases a lot after using spacy"
      ],
      "metadata": {
        "id": "70jvCBFpdn1v"
      },
      "id": "70jvCBFpdn1v"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "57e7ce3d-1b56-4f94-b72a-27a391f7ebe9",
      "metadata": {
        "id": "57e7ce3d-1b56-4f94-b72a-27a391f7ebe9"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import re\n",
        "from langdetect import detect"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = '../job-descriptions/'\n",
        "OUTPUT_DIR = '../software-jobs/'"
      ],
      "metadata": {
        "id": "59J0IjPMbY0L"
      },
      "id": "59J0IjPMbY0L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = os.listdir(DATA_DIR)\n",
        "print(\"Number of files: \", len(files))"
      ],
      "metadata": {
        "id": "ERbb-92MbbKF"
      },
      "id": "ERbb-92MbbKF",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_descriptions = []\n",
        "for file in files:\n",
        "    if \".json\" in file:\n",
        "        with open(DATA_DIR + file, 'r') as f:\n",
        "            data = json.load(f)\n",
        "            data['content'] = re.sub(r'\\n+', '\\n', data['content'])  # remove multiple newlines\n",
        "            data['content'] = re.sub(r'\\t+', '\\t', data['content'])  # remove multiple tabs\n",
        "            data['content'] = re.sub(r'\\r+', '\\r', data['content'])  # remove multiple carriage returns\n",
        "            data['content'] = re.sub(r'\\r\\n+', '\\r\\n', data['content'])  # remove multiple carriage returns\n",
        "            data['content'] = re.sub(r'\\n\\r+', '\\n\\r', data['content'])  # remove multiple carriage returns\n",
        "            data['file'] = file\n",
        "            try:\n",
        "                if detect(data['content']) == 'en':\n",
        "                    job_descriptions.append(data)\n",
        "            except:\n",
        "                print(\"Error in file: \", file)\n",
        "                pass"
      ],
      "metadata": {
        "id": "iGEJqSYCbeqf"
      },
      "id": "iGEJqSYCbeqf",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_titles = [job['title'] for job in job_descriptions]"
      ],
      "metadata": {
        "id": "mNPFViD_bw-Z"
      },
      "id": "mNPFViD_bw-Z",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split job titles into words\n",
        "job_titles_words = []\n",
        "for title in job_titles:\n",
        "    job_titles_words.extend(title.split(' '))"
      ],
      "metadata": {
        "id": "1CdnMRAObzz1"
      },
      "id": "1CdnMRAObzz1",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zDqi4bd3b2hK"
      },
      "id": "zDqi4bd3b2hK",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}